"""
Analysis service for executing stock analysis tasks
"""
import asyncio
import json
import traceback
from datetime import datetime
from typing import Dict, Any, Optional
from motor.motor_asyncio import AsyncIOMotorDatabase
from bson import ObjectId

from models.user import UserInDB
from models.analysis import (
    AnalysisRequest,
    AnalysisStatus,
    AnalysisResult,
    MarketType
)
from core.database import get_database, get_redis
from core.exceptions import AnalysisException
from core.database import Depends

# Import TradingAgents components
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

# Import logging
from tradingagents.utils.logging_manager import get_logger
logger = get_logger('analysis_service')


class AnalysisService:
    """Service for executing stock analysis tasks"""
    
    def __init__(self, db: AsyncIOMotorDatabase, redis_client):
        self.db = db
        self.redis = redis_client
        self._trading_graphs = {}  # Cache for TradingAgentsGraph instances
    
    async def execute_analysis(
        self,
        analysis_id: str,
        analysis_request: AnalysisRequest,
        user: UserInDB
    ):
        """
        Execute analysis task in background
        """
        try:
            logger.info(f"ðŸš€ Starting analysis {analysis_id} for user {user.username}")
            
            # Update status to running
            await self._update_analysis_status(
                analysis_id,
                AnalysisStatus.RUNNING,
                progress=0.0,
                message="Initializing analysis..."
            )
            
            # Get or create TradingAgentsGraph instance
            trading_graph = await self._get_trading_graph(analysis_request, user)
            
            # Update progress with detailed steps
            await self._update_progress(analysis_id, 5.0, "ðŸ” éªŒè¯è‚¡ç¥¨ä»£ç å’Œå¸‚åœºä¿¡æ¯...", "æ•°æ®éªŒè¯")
            await asyncio.sleep(1)  # è®©ç”¨æˆ·çœ‹åˆ°è¿™ä¸ªæ­¥éª¤
            
            # Prepare analysis parameters
            await self._update_progress(analysis_id, 10.0, "âš™ï¸ é…ç½®åˆ†æžå‚æ•°å’Œæ¨¡åž‹è®¾ç½®...", "å‚æ•°é…ç½®")
            await asyncio.sleep(1)
            stock_code = analysis_request.stock_code
            analysis_date = analysis_request.analysis_date or datetime.now().strftime("%Y-%m-%d")
            
            # Convert stock code format if needed
            formatted_stock_code = self._format_stock_code(stock_code, analysis_request.market_type)
            
            logger.info(f"ðŸ“Š Executing analysis for {formatted_stock_code} on {analysis_date}")
            
            # Update progress
            await self._update_progress(analysis_id, 15.0, "ðŸš€ åˆå§‹åŒ–AIåˆ†æžå¼•æ“Ž...", "å¼•æ“Žåˆå§‹åŒ–")
            await asyncio.sleep(1)
            await self._update_progress(analysis_id, 20.0, "ðŸ¤– åŠ è½½æ™ºèƒ½åˆ†æžæ¨¡åž‹...", "æ¨¡åž‹åŠ è½½")
            await asyncio.sleep(1)
            
            # Execute the analysis
            final_state, decision = await self._run_trading_analysis(
                trading_graph,
                formatted_stock_code,
                analysis_date,
                analysis_id
            )
            
            # åˆ†æžå®ŒæˆåŽçš„å¤„ç†
            await self._update_progress(analysis_id, 100.0, "âœ… åˆ†æžæˆåŠŸå®Œæˆï¼", "å®Œæˆ")
            
            # Process and format results
            result_data = await self._process_analysis_results(final_state, decision)
            
            # Update analysis with results
            await self._complete_analysis(analysis_id, result_data)
            
            logger.info(f"âœ… Analysis {analysis_id} completed successfully")
            
        except Exception as e:
            logger.error(f"âŒ Analysis {analysis_id} failed: {str(e)}")
            logger.error(traceback.format_exc())
            
            await self._fail_analysis(analysis_id, str(e))
    
    async def _get_trading_graph(
        self,
        analysis_request: AnalysisRequest,
        user: UserInDB
    ) -> TradingAgentsGraph:
        """
        Get or create TradingAgentsGraph instance with user configuration
        """
        # Create config based on user preferences and request
        config = DEFAULT_CONFIG.copy()
        
        # Apply LLM configuration if provided
        if analysis_request.llm_config:
            config.update(analysis_request.llm_config)
        
        # Apply custom parameters if provided
        if analysis_request.custom_params:
            config.update(analysis_request.custom_params)
        
        # Set market-specific configurations
        if analysis_request.market_type == MarketType.US:
            config["market_type"] = "us"
        elif analysis_request.market_type == MarketType.HK:
            config["market_type"] = "hk"
        else:
            config["market_type"] = "cn"
        
        # Create cache key for this configuration
        config_key = self._get_config_key(config, analysis_request.analysts)
        
        # Return cached instance if available
        if config_key in self._trading_graphs:
            return self._trading_graphs[config_key]
        
        # Create new TradingAgentsGraph instance
        selected_analysts = analysis_request.analysts or ["market", "news", "fundamentals"]
        
        trading_graph = TradingAgentsGraph(
            selected_analysts=selected_analysts,
            debug=False,  # Set to False for production
            config=config
        )
        
        # Cache the instance
        self._trading_graphs[config_key] = trading_graph
        
        return trading_graph
    
    async def _run_trading_analysis(
        self,
        trading_graph: TradingAgentsGraph,
        stock_code: str,
        analysis_date: str,
        analysis_id: str
    ):
        """
        Run the TradingAgents analysis with real-time progress tracking
        """
        # Check for cancellation
        if await self._is_cancelled(analysis_id):
            raise AnalysisException("Analysis was cancelled")
        
        # Define progress callback for real-time updates
        async def progress_callback(message: str, step: int = None, total_steps: int = None, llm_result: str = None, analyst_type: str = None):
            """Progress callback for real-time updates - æ”¯æŒLLMç»“æžœä¼ é€’"""
            try:
                # Calculate progress based on step (7 total steps)
                if step is not None:
                    # ç¡®ä¿stepä»Ž0å¼€å§‹ï¼Œè®¡ç®—æ­£ç¡®çš„è¿›åº¦ç™¾åˆ†æ¯”
                    progress_percentage = ((step + 1) / 7.0) * 80 + 20  # 20-100%èŒƒå›´ï¼Œå‰é¢20%ç”¨äºŽåˆå§‹åŒ–
                    step_names = ["è‚¡ç¥¨è¯†åˆ«", "å¸‚åœºåˆ†æž", "åŸºæœ¬é¢åˆ†æž", "æ–°é—»åˆ†æž", "æƒ…ç»ªåˆ†æž", "æŠ•èµ„è¾©è®º", "é£Žé™©è¯„ä¼°"]
                    step_name = step_names[min(step, 6)]
                    current_step_number = step + 1  # ä¼ é€’ç»™å‰ç«¯çš„æ­¥éª¤ç¼–å·ï¼ˆ1-7ï¼‰
                    await self._update_progress(analysis_id, progress_percentage, message, step_name, llm_result, analyst_type, current_step_number)
                else:
                    # Auto-detect step from message
                    if "è‚¡ç¥¨è¯†åˆ«" in message or "è‚¡ç¥¨ç±»åž‹" in message or "è¯†åˆ«è‚¡ç¥¨" in message:
                        await self._update_progress(analysis_id, 31.4, message, "è‚¡ç¥¨è¯†åˆ«", llm_result, analyst_type, 1)
                    elif "å¸‚åœºåˆ†æžå¸ˆ" in message or "Market Analyst" in message or "æŠ€æœ¯åˆ†æž" in message:
                        await self._update_progress(analysis_id, 42.9, message, "å¸‚åœºåˆ†æž", llm_result, analyst_type, 2)
                    elif "åŸºæœ¬é¢åˆ†æžå¸ˆ" in message or "Fundamentals Analyst" in message or "è´¢åŠ¡åˆ†æž" in message:
                        await self._update_progress(analysis_id, 54.3, message, "åŸºæœ¬é¢åˆ†æž", llm_result, analyst_type, 3)
                    elif "æ–°é—»åˆ†æžå¸ˆ" in message or "News Analyst" in message or "æ–°é—»" in message:
                        await self._update_progress(analysis_id, 65.7, message, "æ–°é—»åˆ†æž", llm_result, analyst_type, 4)
                    elif "ç¤¾äº¤åª’ä½“åˆ†æžå¸ˆ" in message or "Social Media Analyst" in message or "æƒ…ç»ª" in message:
                        await self._update_progress(analysis_id, 77.1, message, "æƒ…ç»ªåˆ†æž", llm_result, analyst_type, 5)
                    elif any(keyword in message for keyword in ["Bull Researcher", "Bear Researcher", "Research Manager", "æŠ•èµ„è¾©è®º", "å¤šç©º"]):
                        await self._update_progress(analysis_id, 88.6, message, "æŠ•èµ„è¾©è®º", llm_result, analyst_type, 6)
                    elif any(keyword in message for keyword in ["Risk Judge", "é£Žé™©ç®¡ç†", "Risky Analyst", "Safe Analyst", "é£Žé™©è¯„ä¼°"]):
                        await self._update_progress(analysis_id, 100.0, message, "é£Žé™©è¯„ä¼°", llm_result, analyst_type, 7)
                    else:
                        # é»˜è®¤æƒ…å†µï¼Œä¸æ›´æ–°æ­¥éª¤ç¼–å·
                        await self._update_progress(analysis_id, None, message, None, llm_result, analyst_type)
            except Exception as e:
                logger.error(f"Progress callback error: {e}")
        
        # Run the analysis in a separate thread with progress callback
        loop = asyncio.get_event_loop()
        
        def run_analysis():
            # Create a wrapper to handle async callback in sync context
            def sync_progress_callback(message: str, step: int = None, total_steps: int = None, llm_result: str = None, analyst_type: str = None):
                # Schedule the async callback - æ”¯æŒLLMç»“æžœä¼ é€’
                try:
                    future = asyncio.run_coroutine_threadsafe(progress_callback(message, step, total_steps, llm_result, analyst_type), loop)
                    future.result(timeout=1.0)  # Wait up to 1 second
                except Exception as e:
                    logger.error(f"Sync progress callback error: {e}")
            
            return trading_graph.propagate(stock_code, analysis_date, sync_progress_callback)
        
        # Execute analysis with real-time progress updates
        final_state, decision = await loop.run_in_executor(None, run_analysis)
        
        return final_state, decision
    
    async def _process_analysis_results(
        self,
        final_state: Dict[str, Any],
        decision: Any
    ) -> AnalysisResult:
        """
        Process and format analysis results
        """
        # Extract different types of analysis from the final state
        messages = final_state.get("messages", [])
        
        # Initialize result components
        summary = {}
        technical_analysis = {}
        fundamental_analysis = {}
        news_analysis = {}
        risk_assessment = {}
        charts = []
        
        # Process messages to extract analysis results
        for message in messages:
            if hasattr(message, 'content'):
                content = message.content
                
                # Determine message type and extract relevant information
                if "Market Analyst" in str(message.name) if hasattr(message, 'name') else False:
                    technical_analysis = self._extract_technical_analysis(content)
                elif "Fundamentals Analyst" in str(message.name) if hasattr(message, 'name') else False:
                    fundamental_analysis = self._extract_fundamental_analysis(content)
                elif "News Analyst" in str(message.name) if hasattr(message, 'name') else False:
                    news_analysis = self._extract_news_analysis(content)
                elif "Risk Judge" in str(message.name) if hasattr(message, 'name') else False:
                    risk_assessment = self._extract_risk_assessment(content)
        
        # Extract final decision
        if hasattr(decision, 'content'):
            summary = {
                "final_decision": decision.content,
                "recommendation": self._extract_recommendation(decision.content),
                "confidence_score": self._extract_confidence_score(decision.content)
            }
        else:
            summary = {
                "final_decision": str(decision),
                "recommendation": "HOLD",  # Default
                "confidence_score": 0.5
            }
        
        return AnalysisResult(
            summary=summary,
            technical_analysis=technical_analysis,
            fundamental_analysis=fundamental_analysis,
            news_analysis=news_analysis,
            risk_assessment=risk_assessment,
            charts=charts,
            raw_data={
                "final_state": final_state,
                "decision": str(decision)
            }
        )
    
    def _extract_technical_analysis(self, content: str) -> Dict[str, Any]:
        """Extract technical analysis information"""
        return {
            "content": content,
            "indicators": {},  # TODO: Parse technical indicators
            "trends": {},      # TODO: Parse trend analysis
            "signals": {}      # TODO: Parse trading signals
        }
    
    def _extract_fundamental_analysis(self, content: str) -> Dict[str, Any]:
        """Extract fundamental analysis information"""
        return {
            "content": content,
            "financials": {},  # TODO: Parse financial metrics
            "valuation": {},   # TODO: Parse valuation metrics
            "growth": {}       # TODO: Parse growth metrics
        }
    
    def _extract_news_analysis(self, content: str) -> Dict[str, Any]:
        """Extract news analysis information"""
        return {
            "content": content,
            "sentiment": "neutral",  # TODO: Parse sentiment
            "key_events": [],        # TODO: Parse key events
            "impact_score": 0.5      # TODO: Parse impact score
        }
    
    def _extract_risk_assessment(self, content: str) -> Dict[str, Any]:
        """Extract risk assessment information"""
        return {
            "content": content,
            "risk_level": "medium",  # TODO: Parse risk level
            "risk_factors": [],      # TODO: Parse risk factors
            "risk_score": 0.5        # TODO: Parse risk score
        }
    
    def _extract_recommendation(self, content: str) -> str:
        """Extract investment recommendation from content"""
        content_lower = content.lower()
        if "buy" in content_lower or "bullish" in content_lower:
            return "BUY"
        elif "sell" in content_lower or "bearish" in content_lower:
            return "SELL"
        else:
            return "HOLD"
    
    def _extract_confidence_score(self, content: str) -> float:
        """Extract confidence score from content"""
        # TODO: Implement more sophisticated confidence extraction
        return 0.7  # Default confidence score
    
    def _format_stock_code(self, stock_code: str, market_type: MarketType) -> str:
        """
        Format stock code according to market conventions
        """
        stock_code = stock_code.upper()
        
        if market_type == MarketType.CN:
            # Chinese stocks might need exchange suffix
            if len(stock_code) == 6 and stock_code.isdigit():
                if stock_code.startswith(('60', '68')):
                    return f"{stock_code}.SH"  # Shanghai
                elif stock_code.startswith(('00', '30')):
                    return f"{stock_code}.SZ"  # Shenzhen
            return stock_code
        elif market_type == MarketType.HK:
            # HK stocks might need .HK suffix
            if stock_code.isdigit():
                return f"{stock_code}.HK"
            return stock_code
        else:
            # US stocks usually don't need suffix
            return stock_code
    
    def _get_config_key(self, config: Dict[str, Any], analysts: list) -> str:
        """
        Generate cache key for configuration
        """
        key_parts = [
            config.get("llm_provider", "default"),
            config.get("market_type", "cn"),
            "-".join(sorted(analysts or []))
        ]
        return "|".join(key_parts)
    
    async def _update_analysis_status(
        self,
        analysis_id: str,
        status: AnalysisStatus,
        progress: float = None,
        message: str = None
    ):
        """
        Update analysis status in database
        """
        update_data = {"status": status.value}
        
        if progress is not None:
            update_data["progress"] = progress
        
        # å¦‚æžœçŠ¶æ€å˜ä¸ºRUNNINGï¼Œä¸”æ•°æ®åº“ä¸­è¿˜æ²¡æœ‰started_atï¼Œåˆ™è®¾ç½®å¼€å§‹æ—¶é—´
        if status == AnalysisStatus.RUNNING:
            # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²ç»æœ‰started_at
            analysis_doc = await self.db.analyses.find_one({"_id": ObjectId(analysis_id)})
            if analysis_doc and not analysis_doc.get("started_at"):
                update_data["started_at"] = datetime.utcnow()
                logger.info(f"ðŸš€ Analysis {analysis_id} started at {update_data['started_at']}")
        elif status in [AnalysisStatus.COMPLETED, AnalysisStatus.FAILED, AnalysisStatus.CANCELLED]:
            update_data["completed_at"] = datetime.utcnow()
        
        if message:
            if status == AnalysisStatus.FAILED:
                update_data["error_message"] = message
        
        await self.db.analyses.update_one(
            {"_id": ObjectId(analysis_id)},
            {"$set": update_data}
        )
    
    async def _update_progress(
        self,
        analysis_id: str,
        progress: float = None,
        message: str = None,
        current_step: str = None,
        llm_result: str = None,
        analyst_type: str = None,
        current_step_number: int = None
    ):
        """
        Update analysis progress in Redis for real-time updates
        """
        # è®¡ç®—å·²ç”¨æ—¶é—´
        elapsed_time = 0
        estimated_remaining = 0
        
        try:
            # ä»Žæ•°æ®åº“èŽ·å–åˆ†æžå¼€å§‹æ—¶é—´
            analysis_doc = await self.db.analyses.find_one({"_id": ObjectId(analysis_id)})
            if analysis_doc and analysis_doc.get("started_at"):
                started_at = analysis_doc["started_at"]
                elapsed_time = (datetime.utcnow() - started_at).total_seconds()
                
                # æ ¹æ®å½“å‰è¿›åº¦ä¼°ç®—å‰©ä½™æ—¶é—´
                if progress and progress > 0:
                    total_estimated_time = elapsed_time * (100.0 / progress)
                    estimated_remaining = max(0, total_estimated_time - elapsed_time)
        except Exception as e:
            logger.warning(f"Failed to calculate elapsed time: {e}")
        
        redis_key = f"analysis_progress:{analysis_id}"

        # è¯»å–çŽ°æœ‰è¿›åº¦ï¼Œé¿å…è¦†ç›–å·²æœ‰çš„progresså­—æ®µ
        existing_progress_data = {}
        try:
            cached_progress = await self.redis.get(redis_key)
            if cached_progress:
                existing_progress_data = json.loads(cached_progress)
        except Exception as e:
            logger.warning(f"Failed to load existing progress from Redis: {e}")

        # æž„å»ºè¿›åº¦æ•°æ®ï¼Œé»˜è®¤ç»§æ‰¿å·²æœ‰å­—æ®µ
        progress_data = dict(existing_progress_data or {})
        progress_data.update({
            "status": "running",  # æ·»åŠ çŠ¶æ€ä¿¡æ¯
            "elapsed_time": elapsed_time,
            "estimated_remaining": estimated_remaining,
            "updated_at": datetime.utcnow().isoformat()
        })
        
        # åªåœ¨æœ‰è¿›åº¦å€¼æ—¶æ›´æ–°è¿›åº¦ç›¸å…³å­—æ®µ
        if progress is not None:
            progress_data["progress"] = progress
            progress_data["progress_percentage"] = progress / 100.0  # æ·»åŠ 0-1æ ¼å¼çš„è¿›åº¦
        
        # åªåœ¨æœ‰æ¶ˆæ¯æ—¶æ›´æ–°æ¶ˆæ¯
        if message is not None:
            progress_data["message"] = message
        
        # åªåœ¨æœ‰æ­¥éª¤ä¿¡æ¯æ—¶æ›´æ–°æ­¥éª¤
        if current_step is not None:
            progress_data["current_step_name"] = current_step
        
        # åªåœ¨æœ‰æ­¥éª¤ç¼–å·æ—¶æ›´æ–°æ­¥éª¤ç¼–å·
        if current_step_number is not None:
            progress_data["current_step"] = current_step_number
            progress_data["total_steps"] = 7
        
        # æ·»åŠ LLMç»“æžœä¿¡æ¯
        if llm_result:
            progress_data["llm_result"] = llm_result
        if analyst_type:
            progress_data["analyst_type"] = analyst_type
        await self.redis.setex(
            redis_key,
            3600,  # 1 hour TTL
            json.dumps(progress_data)
        )
        
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        if progress is not None:
            logger.info(f"ðŸ“Š Progress updated: {progress}% - {message} (Redis key: {redis_key})")
        else:
            logger.info(f"ðŸ“Š Progress message updated: {message} (Redis key: {redis_key})")
        
        # åªåœ¨æœ‰è¿›åº¦å€¼æ—¶æ›´æ–°æ•°æ®åº“
        if progress is not None:
            await self.db.analyses.update_one(
                {"_id": ObjectId(analysis_id)},
                {"$set": {"progress": progress}}
            )
    
    async def _complete_analysis(self, analysis_id: str, result_data: AnalysisResult):
        """
        Mark analysis as completed with results
        """
        await self.db.analyses.update_one(
            {"_id": ObjectId(analysis_id)},
            {
                "$set": {
                    "status": AnalysisStatus.COMPLETED.value,
                    "progress": 100.0,
                    "result_data": result_data.dict(),
                    "completed_at": datetime.utcnow()
                }
            }
        )
        
        # Cache result in Redis
        await self.redis.setex(
            f"analysis_result:{analysis_id}",
            86400,  # 24 hours TTL
            json.dumps(result_data.dict())
        )
        
        # ðŸ”§ æ–°å¢žï¼šä¿å­˜åˆ†æžç»“æžœåˆ°MongoDBï¼ˆç”¨äºŽåŽ†å²è®°å½•å’ŒæŠ¥å‘Šç®¡ç†ï¼‰
        try:
            await self._save_to_mongodb(analysis_id, result_data)
        except Exception as e:
            logger.error(f"Failed to save analysis to MongoDB: {e}")
            # ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
        
        # Clean up progress cache
        await self.redis.delete(f"analysis_progress:{analysis_id}")
    
    async def _fail_analysis(self, analysis_id: str, error_message: str):
        """
        Mark analysis as failed with error message
        """
        await self.db.analyses.update_one(
            {"_id": ObjectId(analysis_id)},
            {
                "$set": {
                    "status": AnalysisStatus.FAILED.value,
                    "error_message": error_message,
                    "completed_at": datetime.utcnow()
                }
            }
        )
        
        # Clean up progress cache
        await self.redis.delete(f"analysis_progress:{analysis_id}")
    
    async def _is_cancelled(self, analysis_id: str) -> bool:
        """
        Check if analysis has been cancelled
        """
        cancel_flag = await self.redis.get(f"analysis_cancel:{analysis_id}")
        return cancel_flag is not None
    
    async def _save_to_mongodb(self, analysis_id: str, result_data: AnalysisResult):
        """
        ä¿å­˜åˆ†æžç»“æžœåˆ°MongoDBï¼ˆç”¨äºŽåŽ†å²è®°å½•å’ŒæŠ¥å‘Šç®¡ç†ï¼‰
        """
        try:
            # èŽ·å–åˆ†æžè®°å½•
            analysis_doc = await self.db.analyses.find_one({"_id": ObjectId(analysis_id)})
            if not analysis_doc:
                logger.error(f"Analysis document not found: {analysis_id}")
                return
            
            # å‡†å¤‡MongoDBæ–‡æ¡£
            stock_symbol = analysis_doc.get("stock_code", "")
            timestamp = datetime.utcnow()
            
            # æž„å»ºåˆ†æžç»“æžœæ‘˜è¦
            summary = result_data.summary or {}
            recommendation = summary.get("recommendation", "HOLD")
            confidence_score = summary.get("confidence_score", 0.5)
            
            # æž„å»ºæŠ¥å‘Šå†…å®¹
            reports = {}
            if result_data.technical_analysis:
                reports["technical_analysis"] = result_data.technical_analysis.get("content", "")
            if result_data.fundamental_analysis:
                reports["fundamental_analysis"] = result_data.fundamental_analysis.get("content", "")
            if result_data.news_analysis:
                reports["news_analysis"] = result_data.news_analysis.get("content", "")
            if result_data.risk_assessment:
                reports["risk_assessment"] = result_data.risk_assessment.get("content", "")
            if summary.get("final_decision"):
                reports["final_decision"] = summary["final_decision"]
            
            # æž„å»ºMongoDBæ–‡æ¡£
            mongodb_doc = {
                "analysis_id": analysis_id,
                "stock_symbol": stock_symbol,
                "analysis_date": timestamp.strftime('%Y-%m-%d'),
                "timestamp": timestamp,
                "status": "completed",
                "source": "backend_api",
                
                # åˆ†æžç»“æžœæ‘˜è¦
                "summary": {
                    "recommendation": recommendation,
                    "confidence_score": confidence_score,
                    "final_decision": summary.get("final_decision", "")
                },
                "analysts": analysis_doc.get("config", {}).get("analysts", []),
                "research_depth": 1,  # é»˜è®¤ç ”ç©¶æ·±åº¦
                
                # æŠ¥å‘Šå†…å®¹
                "reports": reports,
                
                # åŽŸå§‹æ•°æ®
                "raw_data": result_data.raw_data or {},
                
                # å…ƒæ•°æ®
                "created_at": timestamp,
                "updated_at": timestamp,
                "user_id": str(analysis_doc.get("user_id", "")),
                "market_type": analysis_doc.get("market_type", "")
            }
            
            # ä¿å­˜åˆ°MongoDB
            await self.db.analysis_reports.insert_one(mongodb_doc)
            logger.info(f"âœ… Analysis result saved to MongoDB: {analysis_id}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to save analysis to MongoDB: {e}")
            raise


# Dependency function
async def get_analysis_service(
    db: AsyncIOMotorDatabase = Depends(get_database),
    redis_client = Depends(get_redis)
) -> AnalysisService:
    """
    Dependency to get analysis service instance
    """
    return AnalysisService(db, redis_client)
