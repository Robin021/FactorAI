# 模型切换使用说明

## 问题描述
你在系统配置页面看到"模型选择"功能，但下拉框无法选择模型。

## 解决方案
我已经为你添加了缺失的 API 端点 `/config/default-model`，现在模型选择功能应该可以正常工作了。

## 当前可用的模型

根据你的 `.env` 配置，以下模型提供商已经配置好：

### ✅ 阿里百炼 (DashScope)
- qwen-turbo
- qwen-plus
- qwen-max

### ✅ DeepSeek
- deepseek-chat
- deepseek-coder

### ✅ OpenAI
- gpt-4
- gpt-4-turbo
- gpt-3.5-turbo
- gpt-4o-mini

### ✅ OpenRouter
- anthropic/claude-3.5-sonnet
- google/gemini-2.0-flash-exp:free

## 如何使用模型选择功能

1. **启动后端服务**
   ```bash
   cd backend
   python tradingagents_server.py
   ```

2. **启动前端服务**
   ```bash
   cd frontend
   npm run dev
   ```

3. **访问系统配置页面**
   - 打开浏览器访问前端地址（通常是 http://localhost:5173）
   - 登录系统
   - 进入"系统配置" -> "模型选择"标签页

4. **选择模型**
   - 在"提供商"下拉框中选择一个提供商（如 dashscope、deepseek、openai 等）
   - 在"模型"下拉框中选择具体的模型
   - 点击"保存更改"按钮

5. **验证更改**
   - 保存后，系统会显示"默认模型已更新"的提示
   - 新的分析任务将使用新选择的模型

## 添加新的模型提供商

如果你想添加其他模型提供商（如 Google Gemini 或百度千帆），需要：

1. **在 .env 文件中添加 API 密钥**
   ```bash
   # Google Gemini
   GOOGLE_API_KEY=your_google_api_key_here
   
   # 百度千帆
   QIANFAN_API_KEY=your_qianfan_api_key_here
   ```

2. **重启后端服务**
   ```bash
   # 停止当前服务 (Ctrl+C)
   # 重新启动
   python tradingagents_server.py
   ```

3. **刷新配置页面**
   - 在模型选择页面点击"刷新"按钮
   - 新的提供商和模型将出现在下拉框中

## 当前默认配置

```
LLM Provider: openai
Deep Think LLM: o4-mini
Quick Think LLM: gpt-4o-mini
```

## 技术细节

### 新增的 API 端点

1. **GET /api/v1/config/default-model**
   - 获取当前默认模型配置
   - 返回所有可用的模型列表

2. **PUT /api/v1/config/default-model**
   - 更新默认模型配置
   - 参数：
     - `provider`: 提供商名称
     - `model_name`: 模型名称

### 模型检测逻辑

系统会自动检测 `.env` 文件中配置的 API 密钥，只显示已配置的模型提供商。

## 常见问题

### Q: 为什么下拉框是空的？
A: 可能是因为：
1. 后端服务没有启动
2. 没有配置任何 API 密钥
3. 需要刷新页面

### Q: 如何验证模型是否切换成功？
A: 可以：
1. 查看系统配置页面的"当前默认模型"提示
2. 运行测试脚本：`python test_model_config_api.py`
3. 创建一个新的分析任务，查看使用的模型

### Q: 切换模型后，之前的分析会受影响吗？
A: 不会。只有新创建的分析任务会使用新模型，已完成的分析不受影响。

## 推荐配置

根据不同场景推荐使用的模型：

- **快速分析**: qwen-turbo, gpt-3.5-turbo
- **深度分析**: qwen-max, gpt-4, deepseek-chat
- **代码生成**: deepseek-coder
- **成本优化**: google/gemini-2.0-flash-exp:free (OpenRouter 免费模型)

## 下一步

如果你需要：
1. 添加更多模型支持
2. 自定义模型参数（temperature, max_tokens 等）
3. 为不同类型的分析使用不同的模型

请告诉我，我可以继续帮你实现！
