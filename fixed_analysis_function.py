
# å¯åŠ¨çœŸå®žåˆ†æž - ä¿®å¤ç‰ˆæœ¬ï¼Œæ¶ˆé™¤é‡å¤æ‰§è¡Œ
def start_real_analysis(analysis_id: str, symbol: str, market_type: str, analysis_type: str, username: str):
    """å¯åŠ¨çœŸå®žçš„è‚¡ç¥¨åˆ†æž - ä¿®å¤é‡å¤æ‰§è¡Œé—®é¢˜"""
    import threading
    import time
    from datetime import datetime
    
    def analysis_worker():
        try:
            # ç®€åŒ–çš„è·¯å¾„è®¾ç½®
            import sys
            import os
            current_file = Path(__file__).resolve()
            project_root = current_file.parent.parent
            
            if not (project_root / 'tradingagents').exists():
                project_root = Path(os.getcwd()).parent if 'backend' in os.getcwd() else Path(os.getcwd())
                if not (project_root / 'tradingagents').exists():
                    # Try to find tradingagents directory in common locations
                    possible_paths = [
                        Path('/app'),  # Docker container
                        Path.cwd().parent,  # Parent directory
                        Path.cwd(),  # Current directory
                        Path.home() / 'TradingAgents-CN',  # User home
                    ]
                    for path in possible_paths:
                        if (path / 'tradingagents').exists():
                            project_root = path
                            break
                    else:
                        # If still not found, use current directory as fallback
                        project_root = Path(os.getcwd())
            
            if str(project_root) not in sys.path:
                sys.path.insert(0, str(project_root))
            
            # è¿›åº¦å›žè°ƒå‡½æ•°
            def progress_callback(message, step, total_steps):
                try:
                    current_time = time.time()
                    elapsed_time = current_time - analysis_progress_store[analysis_id].get("start_time", current_time)
                    
                    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
                    progress_percentage = (step + 1) / total_steps if total_steps > 0 else 0
                    
                    progress_data = {
                        "status": "running" if progress_percentage < 1.0 else "completed",
                        "current_step": step,
                        "total_steps": total_steps,
                        "progress_percentage": progress_percentage,
                        "progress": progress_percentage * 100,
                        "current_step_name": message,
                        "message": message,
                        "elapsed_time": int(elapsed_time),
                        "last_update": current_time,
                        "timestamp": datetime.now().isoformat(),
                        "updated_at": datetime.now().isoformat()
                    }
                    
                    # æ›´æ–°å†…å­˜å­˜å‚¨
                    analysis_progress_store[analysis_id].update(progress_data)
                    
                    # å†™å…¥Redis
                    if redis_client:
                        try:
                            import json
                            redis_key = f"analysis_progress:{analysis_id}"
                            redis_client.setex(redis_key, 3600, json.dumps(progress_data))
                        except Exception as redis_error:
                            logger.warning(f"Failed to write progress to Redis: {redis_error}")
                    
                    logger.info(f"åˆ†æž {analysis_id} è¿›åº¦: {int(progress_percentage * 100)}% - {message}")
                except Exception as e:
                    logger.error(f"è¿›åº¦å›žè°ƒå¤±è´¥: {e}")
            
            # ç›´æŽ¥æ‰§è¡ŒTradingAgentsåˆ†æž - åªæ‰§è¡Œä¸€æ¬¡
            try:
                from tradingagents.graph.trading_graph import TradingAgentsGraph
                from tradingagents.default_config import DEFAULT_CONFIG
                
                logger.info("âœ… ä½¿ç”¨çœŸå®žTradingAgentsåˆ†æžå¼•æ“Ž")
                
                # åˆ›å»ºé…ç½®
                config = DEFAULT_CONFIG.copy()
                config['llm_provider'] = "deepseek"
                config['deep_think_llm'] = "deepseek-chat"
                config['quick_think_llm'] = "deepseek-chat"
                
                # ç»Ÿä¸€çš„åˆ†æžå¸ˆé…ç½® - é¿å…é‡å¤
                selected_analysts = ["market", "fundamentals", "social"]
                
                # è®°å½•å¼€å§‹æ—¶é—´
                analysis_progress_store[analysis_id]["start_time"] = time.time()
                
                # åˆ›å»ºTradingAgentså›¾å®žä¾‹
                trading_graph = TradingAgentsGraph(selected_analysts=selected_analysts, config=config)
                
                progress_callback("ðŸ” åˆå§‹åŒ–TradingAgentsåˆ†æžå¼•æ“Ž", 0, 7)
                
                # åœ¨å¼€å§‹åˆ†æžå‰æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
                if analysis_progress_store[analysis_id].get("status") == "cancelled":
                    logger.info(f"Analysis {analysis_id} was cancelled before execution")
                    return
                
                # æ‰§è¡Œåˆ†æž - åªæ‰§è¡Œä¸€æ¬¡
                final_state, decision = trading_graph.propagate(
                    company_name=symbol,
                    trade_date=datetime.now().strftime("%Y-%m-%d"),
                    progress_callback=progress_callback
                )
                
                progress_callback("âœ… åˆ†æžå®Œæˆï¼Œæ­£åœ¨æ•´ç†ç»“æžœ", 6, 7)
                
                # æž„å»ºç»“æžœ
                result = {
                    'success': True,
                    'stock_symbol': symbol,
                    'analysis_date': datetime.now().strftime("%Y-%m-%d"),
                    'analysts': selected_analysts,
                    'research_depth': 2,
                    'llm_provider': "deepseek",
                    'llm_model': "deepseek-chat",
                    'state': final_state,
                    'decision': decision
                }
                
            except ImportError as e:
                logger.warning(f"âš ï¸ æ— æ³•å¯¼å…¥TradingAgents: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†æž")
                
                # ç®€åŒ–çš„æ¨¡æ‹Ÿåˆ†æž
                import random
                steps = [
                    ("ðŸ” è¯†åˆ«è‚¡ç¥¨ç±»åž‹å¹¶èŽ·å–åŸºæœ¬ä¿¡æ¯", 0),
                    ("ðŸ“ˆ å¸‚åœºåˆ†æžå¸ˆå¼€å§‹æŠ€æœ¯æŒ‡æ ‡åˆ†æž", 1), 
                    ("ðŸ“Š åŸºæœ¬é¢åˆ†æžå¸ˆå¼€å§‹è´¢åŠ¡æ•°æ®åˆ†æž", 2),
                    ("ðŸ’­ æƒ…ç»ªåˆ†æžå¸ˆå¼€å§‹ç¤¾äº¤åª’ä½“åˆ†æž", 3),
                    ("âš–ï¸ æŠ•èµ„è¾©è®ºï¼šå¤šç©ºè§‚ç‚¹äº¤é”‹", 4),
                    ("ðŸ›¡ï¸ é£Žé™©ç®¡ç†è¯„ä¼°å’Œæœ€ç»ˆå†³ç­–", 5)
                ]
                
                # è®°å½•å¼€å§‹æ—¶é—´
                analysis_progress_store[analysis_id]["start_time"] = time.time()
                
                for step_name, step_num in steps:
                    if analysis_progress_store[analysis_id].get("status") == "cancelled":
                        result = {"success": False, "error": "åˆ†æžå·²å–æ¶ˆ"}
                        break
                    
                    progress_callback(step_name, step_num, 6)
                    time.sleep(random.uniform(2, 5))
                else:
                    result = {
                        'success': True,
                        'stock_symbol': symbol,
                        'analysis_date': datetime.now().strftime("%Y-%m-%d"),
                        'analysis_summary': f'{symbol} è‚¡ç¥¨åˆ†æžå·²å®Œæˆ',
                        'recommendation': 'å»ºè®®å…³æ³¨',
                        'confidence_score': random.uniform(0.6, 0.9)
                    }
            
            # ä¿å­˜åˆ†æžç»“æžœ
            final_status = "completed" if result.get("success", False) else "failed"
            final_message = "åˆ†æžå®Œæˆï¼" if result.get("success", False) else f"åˆ†æžå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
            
            final_progress_data = {
                "status": final_status,
                "progress_percentage": 1.0,
                "progress": 100,
                "current_step": 10,
                "total_steps": 10,
                "message": final_message,
                "current_step_name": final_message,
                "last_message": final_message,
                "results": result,
                "last_update": time.time(),
                "timestamp": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat(),
                "elapsed_time": int(time.time() - analysis_progress_store[analysis_id].get("start_time", time.time())),
                "estimated_time_remaining": 0,
                "estimated_remaining": 0
            }
            
            analysis_progress_store[analysis_id].update(final_progress_data)
            
            # åŒæ—¶å†™å…¥Redis
            if redis_client:
                try:
                    import json
                    redis_key = f"analysis_progress:{analysis_id}"
                    redis_client.setex(redis_key, 3600, json.dumps(final_progress_data))
                    logger.info(f"âœ… åˆ†æžå®ŒæˆçŠ¶æ€å·²å†™å…¥Redis: {analysis_id}")
                except Exception as redis_error:
                    logger.warning(f"Failed to write completion status to Redis: {redis_error}")
            
            # æ›´æ–°MongoDBæ•°æ®åº“çŠ¶æ€
            if mongodb_db is not None:
                try:
                    update_data = {
                        "status": final_status,
                        "progress": 100.0,
                        "completed_at": datetime.utcnow()
                    }
                    
                    # å¦‚æžœåˆ†æžæˆåŠŸï¼Œä¿å­˜ç»“æžœ
                    if result.get('success', False):
                        update_data["result_data"] = result
                    else:
                        update_data["error_message"] = result.get('error', 'æœªçŸ¥é”™è¯¯')
                    
                    # ä½¿ç”¨ç»Ÿä¸€çš„MongoDBæ“ä½œå‡½æ•°
                    safe_mongodb_operation(
                        mongodb_db.analyses.update_one,
                        {"_id": ObjectId(analysis_id)},
                        {"$set": update_data}
                    )
                    
                    logger.info(f"âœ… åˆ†æžå®ŒæˆçŠ¶æ€å·²æ›´æ–°åˆ°æ•°æ®åº“: {analysis_id}")
                except Exception as db_error:
                    logger.warning(f"âš ï¸ æ›´æ–°æ•°æ®åº“çŠ¶æ€å¤±è´¥: {db_error}")
            
            logger.info(f"åˆ†æž {analysis_id} å®Œæˆï¼ŒæˆåŠŸ: {result.get('success', False)}")
            
        except Exception as e:
            logger.error(f"åˆ†æž {analysis_id} æ‰§è¡Œå¤±è´¥: {e}")
            error_progress_data = {
                "status": "failed",
                "progress_percentage": 0,
                "progress": 0,
                "message": f"åˆ†æžå¤±è´¥: {str(e)}",
                "last_message": f"åˆ†æžå¤±è´¥: {str(e)}",
                "error": str(e),
                "last_update": time.time(),
                "timestamp": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat()
            }
            analysis_progress_store[analysis_id].update(error_progress_data)
            
            # åŒæ—¶å†™å…¥Redis
            if redis_client:
                try:
                    import json
                    redis_key = f"analysis_progress:{analysis_id}"
                    redis_client.setex(redis_key, 3600, json.dumps(error_progress_data))
                except Exception as redis_error:
                    logger.warning(f"Failed to write error status to Redis: {redis_error}")
            
            # æ›´æ–°MongoDBæ•°æ®åº“çŠ¶æ€
            if mongodb_db is not None:
                try:
                    # ä½¿ç”¨ç»Ÿä¸€çš„MongoDBæ“ä½œå‡½æ•°
                    safe_mongodb_operation(
                        mongodb_db.analyses.update_one,
                        {"_id": ObjectId(analysis_id)},
                        {"$set": {
                            "status": "failed",
                            "error_message": str(e),
                            "completed_at": datetime.utcnow()
                        }}
                    )
                    
                    logger.info(f"âœ… åˆ†æžå¤±è´¥çŠ¶æ€å·²æ›´æ–°åˆ°æ•°æ®åº“: {analysis_id}")
                except Exception as db_error:
                    logger.warning(f"âš ï¸ æ›´æ–°æ•°æ®åº“çŠ¶æ€å¤±è´¥: {db_error}")
    
    # å¯åŠ¨åŽå°çº¿ç¨‹
    thread = threading.Thread(target=analysis_worker, daemon=True)
    thread.start()
    logger.info(f"å¯åŠ¨çœŸå®žåˆ†æž: {analysis_id} - {symbol} ({market_type})")
